# AI-Ethics-Report
AI &amp; Ethics is a Year 2 Module at TP. It provides students with insights on the usage &amp; implications of AI in daily life. It touches on the risks of applying AI without a certain set of moral &amp; ethical principles, &amp; discusses issues about machine learning; for e.g. 4 types of bias: sample bias, prejudice bias, measurement bias, and algorithm bias.


## AI & Ethics Report Summary
### Case Study: IBM Watson for Oncology (WFO)
#### Background
- Developed by: IBM Watson Health & Memorial Sloan Kettering Cancer Center (mid-2010s).
- Purpose: Assist oncologists with personalized, evidence-based cancer treatment recommendations.
- Technology: Natural Language Processing (NLP) for unstructured medical data + Machine Learning for clinical guidelines.
- Domain: Applied in oncology to improve decision-making, save time, reduce variability, and increase access to knowledge.

### Ethical Issues Identified
1. Overreliance on Limited Training Data
  - Problem: Trained primarily on MSKCC data (U.S.-centric).
  - Impact: Recommendations biased toward U.S. practices; poor global applicability; risk of inequitable cancer care.
  - Comparison: Similar to Amazon’s biased recruiting tool that disadvantaged women.

2. Unrealistic Marketing Claims
  - Problem: IBM overstated WFO’s capabilities as “transformative” for cancer care.
  - Impact:
    - Erosion of trust in AI in healthcare.
    - Financial/reputational damage to hospitals using WFO.
  - Comparison: Similar to Purdue Pharma’s false opioid marketing leading to loss of public trust.

3. Inadequate Domain Knowledge Involvement
- Problem: Oncologists and domain experts were not sufficiently included in system design.
- Impact: Poor usability, disrupted workflows, resistance to adoption.
- Comparison: Boeing 737 MAX failures due to limited pilot input in testing.

### Contributing Factors

- Narrow Data Sources – Reliance on MSKCC data due to partnership, cost, and time constraints.
- Aggressive Marketing Strategy – Driven by ROI pressure and competitive AI landscape.
- Lack of User-Centric Design – Focused on technical AI development, not usability or clinician workflows.

### Proposed Solutions
#### For Data Bias
  - Global Data Diversity – Partner with worldwide healthcare institutions for inclusive datasets.
  - Auditing & Monitoring – Regular stress testing, fairness audits, and real-world validation.

#### For Unrealistic Marketing
  - Chief AI Ethics Officer (CAEO) – Ensure transparency and ethical oversight of claims.
  - Transparent Marketing Guidelines – Set strict standards for AI promotion and claims.

#### For Lack of Domain Expertise
  - Integrate Domain Experts – Involve oncologists at all stages of AI design.
  - Feedback Loops – Continuous user feedback through surveys, digital platforms.
  - Workshops – Developer-clinician collaboration for prototyping and usability testing.


#### Conclusion
- IBM Watson for Oncology’s shortcomings highlight critical lessons in AI adoption:
  - Ethical foresight is essential to prevent bias.
  - Transparency and realistic claims maintain trust.
  - User-centric design ensures practical usability.
- The case underscores the need for diverse data, domain collaboration, governance frameworks, and transparent communication to make AI in healthcare both effective and ethical.
